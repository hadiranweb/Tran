import streamlit as st
import fitz  # PyMuPDF
from huggingface_hub import InferenceClient
import openai
import time
import os
from dotenv import load_dotenv
from fpdf import FPDF
import tempfile
import concurrent.futures
from functools import partial
import json

# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡ ---
load_dotenv()
st.set_page_config(page_title="Ù…ØªØ±Ø¬Ù… Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ", layout="wide")
st.title("ğŸ“– Ù…ØªØ±Ø¬Ù… Ù¾ÛŒØ´Ø±ÙØªÙ‡ PDF Ùˆ Ø²ÛŒØ±Ù†ÙˆÛŒØ³")

# Ø±Ø§Ø³Øªâ€ŒÚ†ÛŒÙ† Ú©Ø±Ø¯Ù† Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ
st.markdown("""
<style>
@font-face {
    font-family: 'Vazir';
    src: url('fonts/Vazirmatn-Regular.ttf') format('truetype');
}

body, p, div, h1, h2, h3, h4, h5, h6 {
    font-family: 'Vazir', 'B Nazanin', Tahoma, sans-serif !important;
    direction: rtl;
    text-align: right;
}
</style>
""", unsafe_allow_html=True)

# --- ØªÙˆØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ ---
def process_pdf_by_page(uploaded_file):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ† ØµÙØ­Ù‡â€ŒØ¨Ù‡â€ŒØµÙØ­Ù‡ Ø§Ø² PDF"""
    uploaded_file.seek(0)
    doc = fitz.open(stream=uploaded_file.read(), filetype="pdf")
    return [page.get_text() for page in doc]

def process_srt_file(uploaded_file):
    """Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ Ø²ÛŒØ±Ù†ÙˆÛŒØ³"""
    content = uploaded_file.read().decode("utf-8")
    blocks = content.split('\n\n')
    return [block.split('\n')[2] for block in blocks if len(block.split('\n')) >= 3]

def translate_text_chunk(text, model_choice, delay=1):
    """ØªØ±Ø¬Ù…Ù‡ Ù‡Ø± Ø¨Ø®Ø´ Ù…ØªÙ† Ø¨Ø§ ØªØ§Ø®ÛŒØ±"""
    time.sleep(delay)  # Ù…Ø¯ÛŒØ±ÛŒØª Rate Limit
    
    if model_choice == "DeepSeek":
        client = InferenceClient(
            model="deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
            token=os.getenv("HUGGINGFACE_TOKEN"))
        prompt = f"Ù…ØªÙ† Ø²ÛŒØ± Ø±Ø§ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø±ÙˆØ§Ù† ØªØ±Ø¬Ù…Ù‡ Ú©Ù†:\n{text}"
        return client.text_generation(prompt, max_new_tokens=2000)
    else:
        openai.api_key = os.getenv("OPENAI_API_KEY")
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Ù…ØªØ±Ø¬Ù… Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ ÙØ§Ø±Ø³ÛŒ"},
                {"role": "user", "content": text}
            ]
        )
        return response.choices[0].message.content

def parallel_translate(chunks, model_choice, max_workers=4):
    """Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÙˆØ§Ø²ÛŒ Ø¨Ø§ ThreadPool"""
    translated_chunks = [None] * len(chunks)
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_index = {
            executor.submit(translate_text_chunk, chunk, model_choice): i 
            for i, chunk in enumerate(chunks)
        }
        
        for future in concurrent.futures.as_completed(future_to_index):
            index = future_to_index[future]
            try:
                translated_chunks[index] = future.result()
            except Exception as e:
                translated_chunks[index] = f"Ø®Ø·Ø§ Ø¯Ø± ØªØ±Ø¬Ù…Ù‡: {str(e)}"
    
    return translated_chunks

def create_pdf(text, filename="ØªØ±Ø¬Ù…Ù‡.pdf"):
    """Ø§ÛŒØ¬Ø§Ø¯ PDF Ø§Ø² Ù…ØªÙ† ØªØ±Ø¬Ù…Ù‡â€ŒØ´Ø¯Ù‡"""
    pdf = FPDF()
    pdf.add_page()
    
  try:
    pdf.add_font('Vazir', '', 'fonts/Vazirmatn-Regular.ttf')  # Ø­Ø°Ù Ù¾Ø§Ø±Ø§Ù…ØªØ± uni
    pdf.add_font('VazirB', 'B', 'fonts/Vazirmatn-Bold.ttf')  # Ø­Ø°Ù Ù¾Ø§Ø±Ø§Ù…ØªØ± uni
    pdf.set_font('Vazir', size=12)
except Exception as e:
    st.warning(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙÙˆÙ†Øª: {str(e)}")
    pdf.add_font("Arial", "", "arial.ttf")  # Ù…Ø´Ø®Øµ Ú©Ø±Ø¯Ù† Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ ÙÙˆÙ†Øª
    pdf.set_font("Arial", size=12)
    
    pdf.multi_cell(0, 10, txt=text, align="R")
    return pdf.output(dest='S').encode('latin1')
    
# --- Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ ---
with st.sidebar:
    st.header("ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ´Ø±ÙØªÙ‡")
    file_type = st.radio(
        "Ù†ÙˆØ¹ ÙØ§ÛŒÙ„ ÙˆØ±ÙˆØ¯ÛŒ:",
        ["PDF", "Ø²ÛŒØ±Ù†ÙˆÛŒØ³ (SRT)", "Ù…ØªÙ† Ø³Ø§Ø¯Ù‡"]
    )
    
    model_choice = st.radio(
        "Ù…Ø¯Ù„ ØªØ±Ø¬Ù…Ù‡:",
        ["DeepSeek", "OpenAI"]
    )
    
    parallel_enabled = st.checkbox("ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÙˆØ§Ø²ÛŒ", value=True)
    max_workers = st.slider("ØªØ¹Ø¯Ø§Ø¯ ThreadÙ‡Ø§", 1, 8, 4) if parallel_enabled else 1

uploaded_file = st.file_uploader(
    "ÙØ§ÛŒÙ„ Ø®ÙˆØ¯ Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯", 
    type=["pdf", "txt", "srt"],
    help="PDF, ÙØ§ÛŒÙ„ Ù…ØªÙ†ÛŒ ÛŒØ§ Ø²ÛŒØ±Ù†ÙˆÛŒØ³ SRT"
)

if uploaded_file:
    st.success(f"âœ… ÙØ§ÛŒÙ„ {uploaded_file.name} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø¯!")
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø­ØªÙˆØ§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ ÙØ§ÛŒÙ„
    if file_type == "PDF":
        chunks = process_pdf_by_page(uploaded_file)
    elif file_type == "Ø²ÛŒØ±Ù†ÙˆÛŒØ³ (SRT)":
        chunks = process_srt_file(uploaded_file)
    else:
        chunks = [uploaded_file.read().decode("utf-8")]
    
    st.info(f"ğŸ” {len(chunks)} Ø¨Ø®Ø´ Ù‚Ø§Ø¨Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯")

    if st.button("Ø´Ø±ÙˆØ¹ ØªØ±Ø¬Ù…Ù‡", type="primary"):
        progress_bar = st.progress(0)
        status_text = st.empty()
        result_area = st.empty()
        
        start_time = time.time()
        
        if parallel_enabled and len(chunks) > 1:
            translated = parallel_translate(chunks, model_choice, max_workers)
        else:
            translated = []
            for i, chunk in enumerate(chunks):
                progress = (i + 1) / len(chunks)
                progress_bar.progress(progress)
                status_text.text(f"Ø¯Ø± Ø­Ø§Ù„ ØªØ±Ø¬Ù…Ù‡ Ø¨Ø®Ø´ {i + 1}/{len(chunks)}...")
                translated.append(translate_text_chunk(chunk, model_choice))
        
        # Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬
        full_translation = "\n\n".join(translated)
        result_area.text_area("ØªØ±Ø¬Ù…Ù‡ Ú©Ø§Ù…Ù„", full_translation, height=400)
        
        # Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù¾Ø±Ø¯Ø§Ø²Ø´
        elapsed_time = time.time() - start_time
        st.success(f"â±ï¸ ØªØ±Ø¬Ù…Ù‡ Ú©Ø§Ù…Ù„ Ø´Ø¯! Ø²Ù…Ø§Ù† Ù¾Ø±Ø¯Ø§Ø²Ø´: {elapsed_time:.2f} Ø«Ø§Ù†ÛŒÙ‡")
        
        # Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù†ØªØ§ÛŒØ¬
        col1, col2 = st.columns(2)
        with col1:
            st.download_button(
                "Ø¯Ø§Ù†Ù„ÙˆØ¯ ØªØ±Ø¬Ù…Ù‡ (PDF)",
                data=create_pdf(full_translation),
                file_name=f"ØªØ±Ø¬Ù…Ù‡_{uploaded_file.name.split('.')[0]}.pdf",
                mime="application/pdf"
            )
        with col2:
            st.download_button(
                "Ø¯Ø§Ù†Ù„ÙˆØ¯ ØªØ±Ø¬Ù…Ù‡ (TXT)",
                data=full_translation,
                file_name=f"ØªØ±Ø¬Ù…Ù‡_{uploaded_file.name.split('.')[0]}.txt",
                mime="text/plain"
            )

        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ø­Ø§ÙØ¸Ù‡ Ù…ÙˆÙ‚Øª
        st.session_state['last_translation'] = full_translation
